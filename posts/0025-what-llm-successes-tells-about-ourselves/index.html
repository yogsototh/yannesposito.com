<!doctype html><html lang=en><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>What LLM successes tells about ourselves?</title><meta name=author content="Yann Esposito"><meta name=description content="And if Human praised mind was in
fact not much than mostly an LLM with a few other layers of features."><meta name=keywords content="blog static"><link rel=stylesheet href=/css/y.css><link rel=alternate type=application/rss+xml href=/rss.xml><link rel=icon href=/favicon.ico><meta name=theme-color media="(prefers-color-scheme: light)" content="#d84100"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#2E3440"><header><div id=logo><a href=/><div class=vis-hidden>Go to Home</div><svg width="5em" viewBox="0 0 64 64"><circle cx="32" cy="32" r="30" stroke="#a3aec2" stroke-width="1" fill="#2e3440"/><circle class="i1" cx="32" cy="32" r="12" stroke="#800" stroke-width="1" fill="#c20"/><circle class="i0" cx="32" cy="32" r="5" stroke-width="1" stroke="#f60" fill="#fa0"/><ellipse class="e" cx="32" cy="14" rx="14" ry="8" stroke-width="0" fill="#fff"/></svg></a></div><div class=content><h1>What LLM successes tells about ourselves?</h1><div class=meta><span class=yyydate>[2023-05-13 Sat]</span> on
<a href=https://her.esy.fun><span class=author>Yann Esposito</span>'s blog</a></div><div class=abstract>And if Human praised mind was in fact not much than mostly an LLM with a
few other layers of features.</div></div></header><main id=content><article><p>I would date the <em>AI renaissance</em> from 2006 when deep-learning
was co-discovered<a href=#fn1 class=footnote-ref id=fnref1 role=doc-noteref><sup>1</sup></a> by different researchers. More
recently we discovered large language models (LLMs) that are so stunning
this really is the new trend right now. A lot has been written about it
already, but one aspect of the discussion I find lacking is how this
change how we could look at ourselves Human.<p>If you take the time to read <a href=https://arxiv.html/pdf/2303.12712.pdf>Sparks of General
Artificial Intelligence: Early Experiments</a> it is clear that AI
progress toward something closer and closer to us Humans. In fact, for
some specific cases, the AI has even super-human competences.<p>So, if LLMs are very good at simulating Human conversation, isn't
this because, our brains are mostly LLM? LLM are not enough to support
all the specter of Human cognition, but are very good at simulating many
aspects of it.<p>I just like this idea that, if our brain function are close to LLMs,
this give us a lot of opportunities to introspect part of Human
behavior.<p>Note this could also be a dangerous bias to have. As other would
consider that Human are not much than LLM, so studying LLMs would be a
very good indicator to Human behavior.<p>But we could use this idea to change how we are reflecting on
different subjects. For example social networks.<p>If you look at how chatGPT behave in a conversation; it is a lot like
us. We start talking about a subject, and suddenly we kind of gravitate
around this subject. In our day-to-day (I would say "normal mode") we
quite often just regurgitate what we heard using our own words. And this
is almost exclusively what LLMs are made for. Regurgitate what they are
trained with.<p>For the most part of our live, we do not create any real new value,
we just regurgitate the same stories and point of view over and over
again. Once in a while, we are exposed to a new concept, a new
experience, and this could affect our internal database of opinions,
point of view, examples, arguments, etc… We add it, and it helps us keep
a conversation next time this subject could be used.<p>It looks like this could partially explain the efficiency of social
networks. A very big part of our interactions with others is sharing our
experience. But it need a lot more "internal power" to be open to
changing our opinion. Even when we appear to change it, most of the time
this is also a social exchange aspect of a conversation. Because, we
just regurgitated a story for which we do not have strong opinion about.
And someone else, has a convincing argument about it, and we either
really add this to our system, or just have a generic response. But the
important aspect of it, is that, for the most part of these exchanges,
they are fruitless. People try to share something, but, most of the
time, almost nothing really get shared to the other minds.<section class="footnotes footnotes-end-of-document" role=doc-endnotes><hr><ol><li id=fn1 role=doc-endnote><p><em>discovered</em> is an important
nuance as this is a lot more powerful than "invented". As a good example
about why you can see this presentation.<a href=#fnref1 class=footnote-back role=doc-backlink>↩︎</a></ol></section></article></main><footer id=postamble class=status><div class=content><nav role=navigation><a href=/index.html>Home</a> |
<a href=/slides.html>Slides</a> |
<a href=/about-me.html>About</a>
<span class=details>(<a href=https://gitea.esy.fun/yogsototh>code</a>
<a href=https://espial.esy.fun/u:yogsototh>bookmarks</a>
<a href=https://espial.esy.fun/u:yogsototh/notes>notes</a>)</span> |
<a href=#logo>↑ Top ↑</a></nav></div></footer>